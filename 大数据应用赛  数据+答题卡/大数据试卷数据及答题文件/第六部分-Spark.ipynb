{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-------+----------+----------+--------+----+--------------------------+-----------+--------+------------+---------------------+---------+----------------+-----------------+\n",
      "|              positionName| salary|min_salary|max_salary|workYear|city|          companyShortName|companySize|district|financeStage|        industryField|thirdType|resumeProcessDay|resumeProcessRate|\n",
      "+--------------------------+-------+----------+----------+--------+----+--------------------------+-----------+--------+------------+---------------------+---------+----------------+-----------------+\n",
      "|       Senior Data Analyst|15k-30k|        15|        30|   3-5年|北京|                  AppAnnie|  150-500人|  东城区|   D轮及以上|           移动互联网| 数据分析|               1|              100|\n",
      "|                数据分析师|15k-20k|        15|        20|   3-5年|北京|北京合生活网络科技有限公司|  150-500人|  朝阳区|  不需要融资|             消费生活| 数据分析|               2|               61|\n",
      "|                数据分析师|14k-25k|        14|        25|   1-3年|北京|                  花生米富|  150-500人|  朝阳区|         B轮|      移动互联网,金融| 数据分析|               2|              100|\n",
      "|        数据分析师（融资）| 8k-13k|         8|        13|   1-3年|北京|                    有利网| 2000人以上|  朝阳区|  不需要融资|                 金融| 数据分析|               0|                0|\n",
      "|       数据分析师-用户增长|15k-30k|        15|        30|   3-5年|北京|                  必要商城|  150-500人|  朝阳区|  不需要融资|                 电商| 数据分析|               1|              100|\n",
      "|            数据分析工程师|15k-30k|        15|        30|   1-3年|北京|                    洋钱罐|  150-500人|  朝阳区|  不需要融资|      移动互联网,金融| 数据分析|               1|              100|\n",
      "|     风险计量部-数据分析师|15k-30k|        15|        30|    不限|北京|                  贝壳金服| 500-2000人|  朝阳区|      未融资|                 金融| 数据分析|               1|               15|\n",
      "|                数据分析师|15k-25k|        15|        25|   3-5年|北京|                  水滴互助| 500-2000人|  朝阳区|         B轮|移动互联网,医疗丨健康| 数据分析|               1|               65|\n",
      "|            数据分析工程师|15k-30k|        15|        30|   3-5年|北京|                  巅峰同道|   50-150人|  朝阳区|         B轮|      金融,移动互联网| 数据分析|               1|               10|\n",
      "|            高级数据分析师|25k-35k|        25|        35|  5-10年|北京|                  发现旅行|   50-150人|  朝阳区|         B轮|                 旅游| 数据分析|               1|               92|\n",
      "|      高级数据分析师(财务)|20k-30k|        20|        30|  5-10年|北京|                  永洪科技|  150-500人|  朝阳区|         C轮|             企业服务| 数据分析|               2|              100|\n",
      "|              数据分析经理|15k-25k|        15|        25|   1-3年|北京|                    美菜网| 2000人以上|  朝阳区|   D轮及以上|                 电商| 数据分析|               0|                0|\n",
      "|              数据分析助理|  5k-6k|         5|         6|    不限|北京|                  骨朵传媒|    15-50人|  朝阳区|         A轮|           移动互联网| 数据分析|               0|                0|\n",
      "|        数据分析助理工程师| 8k-10k|         8|        10|    不限|北京|                  亿脑科技|    15-50人|  朝阳区|      未融资|        硬件,人工智能| 数据分析|               0|                0|\n",
      "|数据分析师（数据策略方向）|15k-30k|        15|        30|   3-5年|北京|                车好多集团| 2000人以上|  朝阳区|   D轮及以上|             消费生活| 数据分析|               1|              100|\n",
      "|   数据分析师-用户画像方向|15k-25k|        15|        25|   3-5年|北京|                  必要商城|  150-500人|  朝阳区|  不需要融资|                 电商| 数据运营|               1|              100|\n",
      "|            高级数据分析师|20k-35k|        20|        35|  5-10年|北京|                  水滴互助| 500-2000人|  朝阳区|         B轮|移动互联网,医疗丨健康| 业务运营|               1|               65|\n",
      "|        数据分析师（金融）|20k-40k|        20|        40|   3-5年|北京|                车好多集团| 2000人以上|  朝阳区|   D轮及以上|             消费生活| 数据分析|               1|              100|\n",
      "|                数据分析师|15k-25k|        15|        25|   1-3年|北京|                    洋钱罐|  150-500人|  朝阳区|  不需要融资|      移动互联网,金融| 数据分析|               1|              100|\n",
      "|                数据分析师|20k-30k|        20|        30|   3-5年|北京|                  闪银奇异| 500-2000人|  朝阳区|   D轮及以上|      移动互联网,金融| 数据分析|               1|              100|\n",
      "+--------------------------+-------+----------+----------+--------+----+--------------------------+-----------+--------+------------+---------------------+---------+----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode, split, regexp_replace\n",
    "spark = SparkSession.builder.master('local').appName('test').getOrCreate()\n",
    "df = spark.read.option('header', True).option('inferSchema', True).csv('./zhaopin.txt') \\\n",
    "    .withColumn('min_salary1', split(col('salary'), '-')[0]) \\\n",
    "    .withColumn('max_salary1', split(col('salary'), '-')[1]) \\\n",
    "    .withColumn('min_salary', regexp_replace(col('min_salary1'), \"k\", \"\")) \\\n",
    "    .withColumn('max_salary', regexp_replace(col('max_salary1'), \"k\", \"\")) \\\n",
    "    .select('positionName','salary','min_salary','max_salary','workYear','city','companyShortName','companySize','district','financeStage','industryField','thirdType','resumeProcessDay','resumeProcessRate')\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+\n",
      "|city|min_salary|max_salary|\n",
      "+----+----------+----------+\n",
      "|杭州|      2190|      3658|\n",
      "|成都|       379|       649|\n",
      "|深圳|      4107|      7163|\n",
      "|重庆|        60|       110|\n",
      "|上海|      6201|     10759|\n",
      "|北京|     11214|     19560|\n",
      "|广州|      1919|      3284|\n",
      "|武汉|       447|       779|\n",
      "+----+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split, regexp_replace\n",
    "from pyspark.sql.types import IntegerType\n",
    "spark = SparkSession.builder.master('local').appName('test').getOrCreate()\n",
    "df = spark.read.option('header', True).option('inferSchema', True).csv('./zhaopin.txt') \\\n",
    "    .withColumn('min_salary1', split(col('salary'), '-')[0]) \\\n",
    "    .withColumn('max_salary1', split(col('salary'), '-')[1]) \\\n",
    "    .withColumn('min_salary', regexp_replace(col('min_salary1'), \"k\", \"\").cast(IntegerType())) \\\n",
    "    .withColumn('max_salary', regexp_replace(col('max_salary1'), \"k\", \"\").cast(IntegerType())) \\\n",
    "    .select('positionName','salary','min_salary','max_salary','workYear','city','companyShortName','companySize','district','financeStage','industryField','thirdType','resumeProcessDay','resumeProcessRate')\n",
    "\n",
    "min_avg = df.groupBy('city') \\\n",
    "    .sum('min_salary') \\\n",
    "    .withColumnRenamed('sum(min_salary)','min_salary')\n",
    "\n",
    "max_avg = df.groupBy('city') \\\n",
    "    .sum('max_salary') \\\n",
    "    .withColumnRenamed('sum(max_salary)','max_salary')\n",
    "\n",
    "min_avg.join(max_avg, ['city'], 'left').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----+\n",
      "|city|  workYear|count|\n",
      "+----+----------+-----+\n",
      "|成都|      不限|   10|\n",
      "|武汉|应届毕业生|    3|\n",
      "|成都|应届毕业生|    1|\n",
      "|广州|    5-10年|   18|\n",
      "|北京|      不限|   67|\n",
      "|杭州|    5-10年|   26|\n",
      "|北京|     1-3年|  168|\n",
      "|成都|    5-10年|    9|\n",
      "|深圳|      不限|   26|\n",
      "|北京|  10年以上|    4|\n",
      "|上海|      不限|   42|\n",
      "|重庆|     3-5年|    3|\n",
      "|深圳|   1年以下|    4|\n",
      "|武汉|      不限|    6|\n",
      "|杭州|      不限|   11|\n",
      "|广州|      不限|   26|\n",
      "|杭州|应届毕业生|    5|\n",
      "|北京|   1年以下|    8|\n",
      "|成都|   1年以下|    2|\n",
      "|深圳|    5-10年|   34|\n",
      "|北京|    5-10年|  113|\n",
      "|深圳|  10年以上|    1|\n",
      "|杭州|   1年以下|    2|\n",
      "|杭州|     3-5年|   72|\n",
      "|上海|应届毕业生|   29|\n",
      "|广州|     3-5年|   57|\n",
      "|北京|     3-5年|  287|\n",
      "|重庆|      不限|    2|\n",
      "|广州|   1年以下|    5|\n",
      "|杭州|     1-3年|   30|\n",
      "|广州|     1-3年|   52|\n",
      "|成都|     1-3年|   13|\n",
      "|上海|     1-3年|  132|\n",
      "|武汉|    5-10年|   11|\n",
      "|武汉|     1-3年|   10|\n",
      "|上海|    5-10年|   57|\n",
      "|武汉|     3-5年|   14|\n",
      "|深圳|     3-5年|  129|\n",
      "|深圳|     1-3年|   75|\n",
      "|北京|应届毕业生|   63|\n",
      "|上海|     3-5年|  164|\n",
      "|深圳|应届毕业生|    6|\n",
      "|上海|   1年以下|    9|\n",
      "|重庆|     1-3年|    3|\n",
      "|广州|应届毕业生|   12|\n",
      "|成都|     3-5年|    8|\n",
      "+----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master('local').appName('test').getOrCreate()\n",
    "df = spark.read.option('header', True).option('inferSchema', True).csv('./zhaopin.txt')\n",
    "\n",
    "df.groupBy('city', 'workYear').count().show(n=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
